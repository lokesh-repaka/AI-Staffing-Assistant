{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJzH34lxKjlJ",
        "outputId": "39c669a2-a2a7-4461-a8cb-ceb50bdf9cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created 'employees.json' with 30 employee records.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Combine all 30 employee records into one list\n",
        "all_employees = [\n",
        "  # --- FIRST 10 RECORDS ---\n",
        "  {\"employeeId\": \"1001\", \"name\": \"Priya Sharma\", \"jobTitle\": \"Senior Software Engineer\", \"department\": \"Engineering\", \"email\": \"priya.sharma@example.com\", \"yearsOfExperience\": 8, \"availability\": \"On Project\", \"manager\": \"John Smith\", \"location\": \"Bangalore (IST)\", \"certifications\": [\"AWS Certified Developer - Associate\"], \"skills\": [{\"skill\": \"Python\", \"proficiency\": \"Expert\"}, {\"skill\": \"AWS\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Java\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"REST APIs\", \"proficiency\": \"Expert\"}, {\"skill\": \"Microservices\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Project QuantumLeap Backend\", \"description\": \"Led development of core microservices, improving API response time by 40%.\"}, {\"projectName\": \"Orion Data Pipeline\", \"description\": \"Optimized data processing scripts in Python, reducing runtime by 30%.\"}]},\n",
        "  {\"employeeId\": \"1002\", \"name\": \"David Chen\", \"jobTitle\": \"Data Analyst\", \"department\": \"Business Intelligence\", \"email\": \"david.chen@example.com\", \"yearsOfExperience\": 4, \"availability\": \"Available\", \"manager\": \"Emily White\", \"location\": \"New York (EST)\", \"certifications\": [\"Tableau Desktop Specialist\"], \"skills\": [{\"skill\": \"SQL\", \"proficiency\": \"Expert\"}, {\"skill\": \"Tableau\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Python\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Data Visualization\", \"proficiency\": \"Expert\"}, {\"skill\": \"Customer Retention Analysis\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"Q3 Sales Performance Analysis\", \"description\": \"Created interactive dashboards to track key sales KPIs for executive review.\"}, {\"projectName\": \"Customer Churn Prediction Model\", \"description\": \"Assisted data science team by cleaning and preparing data for a predictive model.\"}]},\n",
        "  {\"employeeId\": \"1003\", \"name\": \"Maria Garcia\", \"jobTitle\": \"Senior Project Manager\", \"department\": \"PMO\", \"email\": \"maria.garcia@example.com\", \"yearsOfExperience\": 10, \"availability\": \"Partially Available\", \"manager\": \"Alan Turing\", \"location\": \"London (GMT)\", \"certifications\": [\"PMP\", \"Certified ScrumMaster (CSM)\"], \"skills\": [{\"skill\": \"Agile Methodology\", \"proficiency\": \"Expert\"}, {\"skill\": \"Scrum\", \"proficiency\": \"Expert\"}, {\"skill\": \"Stakeholder Communication\", \"proficiency\": \"Expert\"}, {\"skill\": \"Risk Management\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Jira\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Project Phoenix Launch\", \"description\": \"Managed a cross-functional team of 15 to ensure on-time, on-budget delivery of a major product.\"}, {\"projectName\": \"Mobile App Revamp\", \"description\": \"Oversaw complete project lifecycle for the V2 mobile app, from conception to App Store release.\"}]},\n",
        "  {\"employeeId\": \"1004\", \"name\": \"Ben Carter\", \"jobTitle\": \"DevOps Engineer\", \"department\": \"Engineering\", \"email\": \"ben.carter@example.com\", \"yearsOfExperience\": 6, \"availability\": \"On Project\", \"manager\": \"John Smith\", \"location\": \"Remote (EST)\", \"certifications\": [\"AWS Certified DevOps Engineer - Professional\"], \"skills\": [{\"skill\": \"CI/CD\", \"proficiency\": \"Expert\"}, {\"skill\": \"Docker\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Kubernetes\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Terraform\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"System Monitoring\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Infrastructure as Code Initiative\", \"description\": \"Led the migration of legacy server infrastructure to Terraform scripts on AWS.\"}, {\"projectName\": \"CI/CD Pipeline Automation\", \"description\": \"Built and maintained automated testing and deployment pipelines for 5 key applications.\"}]},\n",
        "  {\"employeeId\": \"1005\", \"name\": \"Dr. Evelyn Reed\", \"jobTitle\": \"Lead Data Scientist\", \"department\": \"Data Science\", \"email\": \"evelyn.reed@example.com\", \"yearsOfExperience\": 9, \"availability\": \"Available\", \"manager\": \"Alan Turing\", \"location\": \"Boston (EST)\", \"certifications\": [\"TensorFlow Developer Certificate\"], \"skills\": [{\"skill\": \"Machine Learning\", \"proficiency\": \"Expert\"}, {\"skill\": \"Python\", \"proficiency\": \"Expert\"}, {\"skill\": \"R\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Natural Language Processing (NLP)\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Deep Learning\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"Customer Sentiment Analysis Engine\", \"description\": \"Developed an NLP model to analyze customer feedback, improving product strategy.\"}, {\"projectName\": \"Sales Forecasting Model\", \"description\": \"Built a time-series model to predict quarterly sales with 92% accuracy.\"}]},\n",
        "  {\"employeeId\": \"1006\", \"name\": \"Chloe Davis\", \"jobTitle\": \"Digital Marketing Manager\", \"department\": \"Marketing\", \"email\": \"chloe.davis@example.com\", \"yearsOfExperience\": 7, \"availability\": \"Available\", \"manager\": \"Emily White\", \"location\": \"Chicago (CST)\", \"certifications\": [\"Google Analytics IQ\", \"HubSpot Content Marketing\"], \"skills\": [{\"skill\": \"SEO\", \"proficiency\": \"Expert\"}, {\"skill\": \"Google Analytics\", \"proficiency\": \"Expert\"}, {\"skill\": \"Content Strategy\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Lead Generation\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Social Media Marketing\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Q4 Lead Generation Campaign\", \"description\": \"Managed a $50k ad spend across multiple channels, resulting in a 150% ROI.\"}, {\"projectName\": \"Corporate Website SEO Overhaul\", \"description\": \"Led a project that improved organic search rankings for 20+ key terms to the first page.\"}]},\n",
        "  {\"employeeId\": \"1007\", \"name\": \"Leo Martinez\", \"jobTitle\": \"UI/UX Designer\", \"department\": \"Product\", \"email\": \"leo.martinez@example.com\", \"yearsOfExperience\": 3, \"availability\": \"Available\", \"manager\": \"Maria Garcia\", \"location\": \"San Francisco (PST)\", \"certifications\": [], \"skills\": [{\"skill\": \"Figma\", \"proficiency\": \"Expert\"}, {\"skill\": \"User Research\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Wireframing\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Prototyping\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Design Systems\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"Marketing Site Redesign Mockups\", \"description\": \"Developed high-fidelity, responsive mockups for the new corporate marketing site.\"}, {\"projectName\": \"Mobile App User Onboarding Flow\", \"description\": \"Designed and tested a new, user-friendly onboarding experience that reduced user drop-off by 15%.\"}]},\n",
        "  {\"employeeId\": \"1008\", \"name\": \"Samuel Jones\", \"jobTitle\": \"IT Security Analyst\", \"department\": \"IT Operations\", \"email\": \"samuel.jones@example.com\", \"yearsOfExperience\": 5, \"availability\": \"On Project\", \"manager\": \"John Smith\", \"location\": \"Austin (CST)\", \"certifications\": [\"CompTIA Security+\", \"Certified Ethical Hacker (CEH)\"], \"skills\": [{\"skill\": \"Network Security\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Vulnerability Assessment\", \"proficiency\": \"Expert\"}, {\"skill\": \"SIEM Tools\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Penetration Testing\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Incident Response\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Quarterly Security Audit\", \"description\": \"Conducted vulnerability scans and penetration tests on critical company infrastructure.\"}, {\"projectName\": \"Phishing Awareness Campaign\", \"description\": \"Developed and led a company-wide training program to reduce successful phishing attacks.\"}]},\n",
        "  {\"employeeId\": \"1009\", \"name\": \"Kenji Tanaka\", \"jobTitle\": \"Cloud Infrastructure Engineer\", \"department\": \"Engineering\", \"email\": \"kenji.tanaka@example.com\", \"yearsOfExperience\": 7, \"availability\": \"Partially Available\", \"manager\": \"John Smith\", \"location\": \"Tokyo (JST)\", \"certifications\": [\"Microsoft Certified: Azure Solutions Architect Expert\"], \"skills\": [{\"skill\": \"Azure\", \"proficiency\": \"Expert\"}, {\"skill\": \"Infrastructure as Code\", \"proficiency\": \"Advanced\"}, {\"skill\": \"PowerShell\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Network Architecture\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Cost Optimization\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Azure Cloud Migration\", \"description\": \"Architected and executed the migration of on-premise data centers to Azure.\"}, {\"projectName\": \"Cloud Cost Reduction\", \"description\": \"Implemented policies and automated scripts that reduced monthly cloud spend by 22%.\"}]},\n",
        "  {\"employeeId\": \"1010\", \"name\": \"Olivia White\", \"jobTitle\": \"HR Business Partner\", \"department\": \"Human Resources\", \"email\": \"olivia.white@example.com\", \"yearsOfExperience\": 6, \"availability\": \"Available\", \"manager\": \"Alan Turing\", \"location\": \"London (GMT)\", \"certifications\": [\"SHRM-CP\"], \"skills\": [{\"skill\": \"Employee Relations\", \"proficiency\": \"Expert\"}, {\"skill\": \"Talent Management\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Performance Management\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Recruiting\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"HR Policy\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Annual Performance Review Cycle\", \"description\": \"Coordinated the end-to-end performance review process for the Engineering and Product departments.\"}, {\"projectName\": \"Career Pathing Framework\", \"description\": \"Developed a new framework for career progression and skill development within the company.\"}]},\n",
        "  # --- SECOND 10 RECORDS ---\n",
        "  {\"employeeId\": \"1011\", \"name\": \"Fatima Al-Jamil\", \"jobTitle\": \"QA Engineer\", \"department\": \"Quality Assurance\", \"email\": \"fatima.aljamil@example.com\", \"yearsOfExperience\": 5, \"availability\": \"Available\", \"manager\": \"John Smith\", \"location\": \"Dubai (GST)\", \"certifications\": [\"ISTQB Certified Tester\"], \"skills\": [{\"skill\": \"Automation Testing\", \"proficiency\": \"Expert\"}, {\"skill\": \"Selenium\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Manual Testing\", \"proficiency\": \"Expert\"}, {\"skill\": \"API Testing\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Jira\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Mobile App Automated Test Suite\", \"description\": \"Built a comprehensive automation suite using Selenium, increasing test coverage by 60%.\"}, {\"projectName\": \"QuantumLeap Regression Testing\", \"description\": \"Led the manual regression testing effort before a major release, identifying 12 critical bugs.\"}]},\n",
        "  {\"employeeId\": \"1012\", \"name\": \"James O'Malley\", \"jobTitle\": \"Technical Writer\", \"department\": \"Product\", \"email\": \"james.omalley@example.com\", \"yearsOfExperience\": 6, \"availability\": \"On Project\", \"manager\": \"Maria Garcia\", \"location\": \"Dublin (IST)\", \"certifications\": [], \"skills\": [{\"skill\": \"Technical Documentation\", \"proficiency\": \"Expert\"}, {\"skill\": \"API Documentation\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Markdown\", \"proficiency\": \"Expert\"}, {\"skill\": \"Confluence\", \"proficiency\": \"Advanced\"}, {\"skill\": \"User Guides\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Public Developer Hub Documentation\", \"description\": \"Authored and maintained all API reference guides for external developers.\"}, {\"projectName\": \"Internal Knowledge Base Restructuring\", \"description\": \"Overhauled the company's Confluence space to improve discoverability of information.\"}]},\n",
        "  {\"employeeId\": \"1013\", \"name\": \"Sophie Dubois\", \"jobTitle\": \"Junior Data Scientist\", \"department\": \"Data Science\", \"email\": \"sophie.dubois@example.com\", \"yearsOfExperience\": 2, \"availability\": \"Available\", \"manager\": \"Dr. Evelyn Reed\", \"location\": \"Montreal (EST)\", \"certifications\": [], \"skills\": [{\"skill\": \"Python\", \"proficiency\": \"Advanced\"}, {\"skill\": \"scikit-learn\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Tableau\", \"proficiency\": \"Advanced\"}, {\"skill\": \"SQL\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Jupyter Notebooks\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Customer Segmentation Analysis\", \"description\": \"Performed exploratory data analysis and feature engineering to support a customer segmentation model.\"}, {\"projectName\": \"Data Cleaning for Sales Forecasting\", \"description\": \"Wrote scripts to clean, transform, and validate historical sales data for model training.\"}]},\n",
        "  {\"employeeId\": \"1014\", \"name\": \"Carlos Mendoza\", \"jobTitle\": \"Financial Analyst\", \"department\": \"Finance\", \"email\": \"carlos.mendoza@example.com\", \"yearsOfExperience\": 4, \"availability\": \"Partially Available\", \"manager\": \"Alan Turing\", \"location\": \"Milan (CET)\", \"certifications\": [\"CFA Level II Candidate\"], \"skills\": [{\"skill\": \"Financial Modeling\", \"proficiency\": \"Expert\"}, {\"skill\": \"Microsoft Excel\", \"proficiency\": \"Expert\"}, {\"skill\": \"Budget Forecasting\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Variance Analysis\", \"proficiency\": \"Advanced\"}, {\"skill\": \"SAP\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"FY2024 Annual Budget Planning\", \"description\": \"Developed department-level budget models and consolidated them into the master corporate budget.\"}, {\"projectName\": \"M&A Due Diligence Support\", \"description\": \"Analyzed the financial statements of a potential acquisition target.\"}]},\n",
        "  {\"employeeId\": \"1015\", \"name\": \"Aisha Khan\", \"jobTitle\": \"Customer Support Lead\", \"department\": \"Customer Success\", \"email\": \"aisha.khan@example.com\", \"yearsOfExperience\": 8, \"availability\": \"On Project\", \"manager\": \"Emily White\", \"location\": \"Singapore (SGT)\", \"certifications\": [\"Zendesk Certified Support Admin\"], \"skills\": [{\"skill\": \"Zendesk\", \"proficiency\": \"Expert\"}, {\"skill\": \"Customer De-escalation\", \"proficiency\": \"Expert\"}, {\"skill\": \"Team Leadership\", \"proficiency\": \"Advanced\"}, {\"skill\": \"SLA Management\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Knowledge Base Management\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"APAC Support Team Expansion\", \"description\": \"Hired, onboarded, and trained a team of 5 new Tier-1 support agents for the APAC region.\"}, {\"projectName\": \"Zendesk Implementation\", \"description\": \"Led the project to migrate the entire support operation from legacy software to Zendesk.\"}]},\n",
        "  {\"employeeId\": \"1016\", \"name\": \"Robert Chen\", \"jobTitle\": \"Corporate Legal Counsel\", \"department\": \"Legal\", \"email\": \"robert.chen@example.com\", \"yearsOfExperience\": 9, \"availability\": \"Available\", \"manager\": \"Alan Turing\", \"location\": \"New York (EST)\", \"certifications\": [\"Bar Admission: New York State\"], \"skills\": [{\"skill\": \"Contract Law\", \"proficiency\": \"Expert\"}, {\"skill\": \"Intellectual Property Law\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Regulatory Compliance\", \"proficiency\": \"Expert\"}, {\"skill\": \"Negotiation\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Data Privacy (GDPR, CCPA)\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"GDPR Compliance Overhaul\", \"description\": \"Led the legal team's effort to audit and update all company policies to ensure full GDPR compliance.\"}, {\"projectName\": \"Series B Funding Round\", \"description\": \"Managed all legal documentation and due diligence for the company's successful $50M funding round.\"}]},\n",
        "  {\"employeeId\": \"1017\", \"name\": \"Liam Murphy\", \"jobTitle\": \"Junior Backend Engineer\", \"department\": \"Engineering\", \"email\": \"liam.murphy@example.com\", \"yearsOfExperience\": 1, \"availability\": \"Available\", \"manager\": \"Priya Sharma\", \"location\": \"Remote (CST)\", \"certifications\": [], \"skills\": [{\"skill\": \"Go (Golang)\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Docker\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"PostgreSQL\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Git\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Unit Testing\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"API Endpoint Maintenance\", \"description\": \"Assisted the senior team in fixing bugs and implementing minor features for internal APIs.\"}, {\"projectName\": \"Internal Tool Development\", \"description\": \"Contributed to building a new admin dashboard using Go and PostgreSQL.\"}]},\n",
        "  {\"employeeId\": \"1018\", \"name\": \"Isabella Rossi\", \"jobTitle\": \"Senior Product Manager, Mobile\", \"department\": \"Product\", \"email\": \"isabella.rossi@example.com\", \"yearsOfExperience\": 8, \"availability\": \"On Project\", \"manager\": \"Alan Turing\", \"location\": \"San Francisco (PST)\", \"certifications\": [\"Certified Product Manager (AIPMM)\"], \"skills\": [{\"skill\": \"Product Roadmap\", \"proficiency\": \"Expert\"}, {\"skill\": \"User Stories\", \"proficiency\": \"Expert\"}, {\"skill\": \"A/B Testing\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Market Research\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Mobile Analytics\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Mobile App V3 Launch\", \"description\": \"Defined the feature set, roadmap, and go-to-market strategy for the next-generation mobile application.\"}, {\"projectName\": \"User Personalization Feature\", \"description\": \"Drove development of a new personalization engine from ideation to launch, increasing user engagement by 20%.\"}]},\n",
        "  {\"employeeId\": \"1019\", \"name\": \"Marco Silva\", \"jobTitle\": \"Business Development Representative\", \"department\": \"Sales\", \"email\": \"marco.silva@example.com\", \"yearsOfExperience\": 3, \"availability\": \"Available\", \"manager\": \"Emily White\", \"location\": \"São Paulo (BRT)\", \"certifications\": [\"Salesforce Certified Administrator\"], \"skills\": [{\"skill\": \"Salesforce\", \"proficiency\": \"Expert\"}, {\"skill\": \"Lead Qualification\", \"proficiency\": \"Expert\"}, {\"skill\": \"Cold Calling\", \"proficiency\": \"Advanced\"}, {\"skill\": \"LinkedIn Sales Navigator\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Presentation Skills\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"LATAM Market Entry\", \"description\": \"Responsible for generating the first 50 qualified enterprise leads in the new Latin American market.\"}, {\"projectName\": \"Outbound Sales Cadence Optimization\", \"description\": \"Designed and tested new email and call cadences, improving reply rates by 15%.\"}]},\n",
        "  {\"employeeId\": \"1020\", \"name\": \"Nadia Petrova\", \"jobTitle\": \"Cybersecurity Architect\", \"department\": \"IT Operations\", \"email\": \"nadia.petrova@example.com\", \"yearsOfExperience\": 12, \"availability\": \"Partially Available\", \"manager\": \"John Smith\", \"location\": \"Berlin (CET)\", \"certifications\": [\"CISSP\", \"CISM\"], \"skills\": [{\"skill\": \"Security Architecture\", \"proficiency\": \"Expert\"}, {\"skill\": \"Zero Trust Principles\", \"proficiency\": \"Expert\"}, {\"skill\": \"Cloud Security (AWS, Azure)\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Threat Modeling\", \"proficiency\": \"Expert\"}, {\"skill\": \"Identity & Access Management (IAM)\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Zero Trust Network Implementation\", \"description\": \"Designed and led the multi-year project to roll out a new Zero Trust security paradigm across the enterprise.\"}, {\"projectName\": \"Cloud Security Posture Management\", \"description\": \"Architected the security framework and tooling for the company's multi-cloud environment.\"}]},\n",
        "  # --- THIRD 10 RECORDS ---\n",
        "  {\"employeeId\": \"1021\", \"name\": \"Wei Zhang\", \"jobTitle\": \"Principal Software Engineer\", \"department\": \"Engineering\", \"email\": \"wei.zhang@example.com\", \"yearsOfExperience\": 15, \"availability\": \"Partially Available\", \"manager\": \"Alan Turing\", \"location\": \"Shanghai (CST)\", \"certifications\": [], \"skills\": [{\"skill\": \"System Architecture\", \"proficiency\": \"Expert\"}, {\"skill\": \"Distributed Systems\", \"proficiency\": \"Expert\"}, {\"skill\": \"Go (Golang)\", \"proficiency\": \"Expert\"}, {\"skill\": \"Performance Tuning\", \"proficiency\": \"Expert\"}, {\"skill\": \"Mentorship\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Core Platform Rewrite\", \"description\": \"Led the architectural design for a new, scalable platform, reducing system latency by 60%.\"}, {\"projectName\": \"Technical Debt Reduction Initiative\", \"description\": \"Mentored three engineering teams on best practices, leading to a 40% reduction in critical code bugs.\"}]},\n",
        "  {\"employeeId\": \"1022\", \"name\": \"Anika Patel\", \"jobTitle\": \"Machine Learning Engineer\", \"department\": \"Data Science\", \"email\": \"anika.patel@example.com\", \"yearsOfExperience\": 5, \"availability\": \"On Project\", \"manager\": \"Dr. Evelyn Reed\", \"location\": \"Mumbai (IST)\", \"certifications\": [\"AWS Certified Machine Learning - Specialty\"], \"skills\": [{\"skill\": \"MLOps\", \"proficiency\": \"Expert\"}, {\"skill\": \"PyTorch\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Kubeflow\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Model Deployment\", \"proficiency\": \"Expert\"}, {\"skill\": \"Python\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Recommendation Engine Productionalization\", \"description\": \"Built the CI/CD pipeline and deployment infrastructure for the company's product recommendation model.\"}, {\"projectName\": \"Model Monitoring System\", \"description\": \"Developed a real-time monitoring dashboard to track model drift and performance in production.\"}]},\n",
        "  {\"employeeId\": \"1023\", \"name\": \"Lars Andersen\", \"jobTitle\": \"iOS Developer\", \"department\": \"Engineering\", \"email\": \"lars.andersen@example.com\", \"yearsOfExperience\": 4, \"availability\": \"Available\", \"manager\": \"Isabella Rossi\", \"location\": \"Copenhagen (CET)\", \"certifications\": [], \"skills\": [{\"skill\": \"Swift\", \"proficiency\": \"Expert\"}, {\"skill\": \"SwiftUI\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Xcode\", \"proficiency\": \"Expert\"}, {\"skill\": \"Core Data\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Mobile UI/UX Principles\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Mobile App V2 Feature Development\", \"description\": \"Developed three major features for the flagship iOS app, including a new chat functionality.\"}, {\"projectName\": \"App Performance Optimization\", \"description\": \"Refactored legacy code, which decreased app launch time by 25% and reduced crashes by 50%.\"}]},\n",
        "  {\"employeeId\": \"1024\", \"name\": \"Elena Ivanova\", \"jobTitle\": \"Staff Accountant\", \"department\": \"Finance\", \"email\": \"elena.ivanova@example.com\", \"yearsOfExperience\": 3, \"availability\": \"Available\", \"manager\": \"Carlos Mendoza\", \"location\": \"Remote (EST)\", \"certifications\": [], \"skills\": [{\"skill\": \"GAAP\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Bookkeeping\", \"proficiency\": \"Expert\"}, {\"skill\": \"Accounts Payable/Receivable\", \"proficiency\": \"Expert\"}, {\"skill\": \"Financial Reporting\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"QuickBooks\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Month-End Close Process\", \"description\": \"Managed the accounts receivable reconciliation process, reducing closing time by two days.\"}, {\"projectName\": \"Expense Reporting System Migration\", \"description\": \"Assisted in migrating from a manual expense system to an automated platform, improving employee adoption.\"}]},\n",
        "  {\"employeeId\": \"1025\", \"name\": \"Daniel Miller\", \"jobTitle\": \"Head of Product\", \"department\": \"Product\", \"email\": \"daniel.miller@example.com\", \"yearsOfExperience\": 14, \"availability\": \"On Project\", \"manager\": \"Alan Turing\", \"location\": \"Austin (CST)\", \"certifications\": [], \"skills\": [{\"skill\": \"Product Vision & Strategy\", \"proficiency\": \"Expert\"}, {\"skill\": \"Team Leadership\", \"proficiency\": \"Expert\"}, {\"skill\": \"P&L Management\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Go-to-Market Strategy\", \"proficiency\": \"Expert\"}, {\"skill\": \"Executive Communication\", \"proficiency\": \"Expert\"}], \"projectHistory\": [{\"projectName\": \"Enterprise Platform Launch\", \"description\": \"Led the entire Product division to define, build, and launch a new enterprise SaaS offering, securing 10 major clients in the first year.\"}, {\"projectName\": \"Product Team Reorganization\", \"description\": \"Restructured the product team into agile pods, which increased feature velocity by 30%.\"}]},\n",
        "  {\"employeeId\": \"1026\", \"name\": \"Grace Kim\", \"jobTitle\": \"Content Marketing Specialist\", \"department\": \"Marketing\", \"email\": \"grace.kim@example.com\", \"yearsOfExperience\": 4, \"availability\": \"Available\", \"manager\": \"Chloe Davis\", \"location\": \"Seoul (KST)\", \"certifications\": [\"HubSpot Inbound Marketing\"], \"skills\": [{\"skill\": \"Copywriting\", \"proficiency\": \"Expert\"}, {\"skill\": \"Blogging\", \"proficiency\": \"Expert\"}, {\"skill\": \"Social Media Content\", \"proficiency\": \"Advanced\"}, {\"skill\": \"SEO Writing\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Email Marketing\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"Company Blog Revitalization\", \"description\": \"Wrote 20+ long-form blog posts and case studies, resulting in a 200% increase in organic blog traffic.\"}, {\"projectName\": \"Product Launch Content\", \"description\": \"Created all written content for a major product launch, including website copy, email campaigns, and social media posts.\"}]},\n",
        "  {\"employeeId\": \"1027\", \"name\": \"Tom Washington\", \"jobTitle\": \"IT Help Desk Technician\", \"department\": \"IT Operations\", \"email\": \"tom.washington@example.com\", \"yearsOfExperience\": 2, \"availability\": \"Available\", \"manager\": \"Samuel Jones\", \"location\": \"Chicago (CST)\", \"certifications\": [\"CompTIA A+\"], \"skills\": [{\"skill\": \"Technical Troubleshooting\", \"proficiency\": \"Expert\"}, {\"skill\": \"Active Directory\", \"proficiency\": \"Intermediate\"}, {\"skill\": \"Hardware Support\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Customer Service\", \"proficiency\": \"Expert\"}, {\"skill\": \"O365 Administration\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"New Hire Onboarding IT Support\", \"description\": \"Manages IT setup and support for all new hires, maintaining a 98% satisfaction score.\"}, {\"projectName\": \"Laptop Refresh Program\", \"description\": \"Assisted in imaging and deploying 200 new laptops to employees as part of an annual hardware refresh.\"}]},\n",
        "  {\"employeeId\": \"1028\", \"name\": \"Mei Lin\", \"jobTitle\": \"Supply Chain Analyst\", \"department\": \"Operations\", \"email\": \"mei.lin@example.com\", \"yearsOfExperience\": 6, \"availability\": \"On Project\", \"manager\": \"Alan Turing\", \"location\": \"Shenzhen (CST)\", \"certifications\": [\"Certified in Production and Inventory Management (CPIM)\"], \"skills\": [{\"skill\": \"Logistics Planning\", \"proficiency\": \"Expert\"}, {\"skill\": \"Inventory Management\", \"proficiency\": \"Expert\"}, {\"skill\": \"Demand Forecasting\", \"proficiency\": \"Advanced\"}, {\"skill\": \"SAP SCM\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Data Analysis\", \"proficiency\": \"Intermediate\"}], \"projectHistory\": [{\"projectName\": \"Inventory Optimization Project\", \"description\": \"Analyzed inventory data and implemented a new stocking strategy, reducing carrying costs by 15%.\"}, {\"projectName\": \"Supplier Performance Tracking\", \"description\": \"Developed a scorecard to monitor supplier delivery times and quality, improving on-time delivery rates by 10%.\"}]},\n",
        "  {\"employeeId\": \"1029\", \"name\": \"Javier Castillo\", \"jobTitle\": \"Graphic Designer\", \"department\": \"Marketing\", \"email\": \"javier.castillo@example.com\", \"yearsOfExperience\": 5, \"availability\": \"Available\", \"manager\": \"Chloe Davis\", \"location\": \"Mexico City (CDT)\", \"certifications\": [\"Adobe Certified Expert (ACE) - Illustrator\"], \"skills\": [{\"skill\": \"Adobe Illustrator\", \"proficiency\": \"Expert\"}, {\"skill\": \"Adobe Photoshop\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Branding & Identity\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Visual Design\", \"proficiency\": \"Expert\"}, {\"skill\": \"Infographics\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Corporate Rebranding Initiative\", \"description\": \"Designed the new company logo and created a comprehensive brand style guide for internal and external use.\"}, {\"projectName\": \"Marketing Campaign Visuals\", \"description\": \"Created all digital ad graphics, social media visuals, and infographics for three major marketing campaigns.\"}]},\n",
        "  {\"employeeId\": \"1030\", \"name\": \"Anya Sharma\", \"jobTitle\": \"Solutions Architect (Pre-Sales)\", \"department\": \"Sales\", \"email\": \"anya.sharma@example.com\", \"yearsOfExperience\": 9, \"availability\": \"Partially Available\", \"manager\": \"Emily White\", \"location\": \"Sydney (AEST)\", \"certifications\": [\"AWS Certified Solutions Architect - Professional\"], \"skills\": [{\"skill\": \"Solution Design\", \"proficiency\": \"Expert\"}, {\"skill\": \"Technical Presentations\", \"proficiency\": \"Expert\"}, {\"skill\": \"Cloud Architecture (AWS)\", \"proficiency\": \"Expert\"}, {\"skill\": \"Proof of Concept (PoC) Development\", \"proficiency\": \"Advanced\"}, {\"skill\": \"Stakeholder Management\", \"proficiency\": \"Advanced\"}], \"projectHistory\": [{\"projectName\": \"Enterprise Client A Deal\", \"description\": \"Led the technical pre-sales cycle for a $1.5M deal, designing a custom solution that met all client requirements.\"}, {\"projectName\": \"Product Demo Environment\", \"description\": \"Architected and built a reusable, scalable demo environment in AWS for the entire sales team to use.\"}]}\n",
        "]\n",
        "\n",
        "# Write the data to a file\n",
        "json_file_path = 'employees.json'\n",
        "with open(json_file_path, 'w') as f:\n",
        "    json.dump(all_employees, f, indent=2)\n",
        "\n",
        "print(f\"Successfully created '{json_file_path}' with 30 employee records.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define the file paths\n",
        "json_file = 'employees.json'\n",
        "db_file = 'employees.db'\n",
        "\n",
        "# Optional: Remove old database file if it exists to start fresh\n",
        "if os.path.exists(db_file):\n",
        "    os.remove(db_file)\n",
        "    print(f\"Removed old database file: {db_file}\")"
      ],
      "metadata": {
        "id": "3D1KYmX1KmKl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data from JSON File ---\n",
        "with open(json_file, 'r') as f:\n",
        "    employee_data = json.load(f)\n",
        "    print(f\"Loaded {len(employee_data)} records from {json_file}\")\n",
        "\n",
        "# --- Connect to SQLite Database and Get Cursor ---\n",
        "# This will create the database file if it doesn't exist\n",
        "conn = sqlite3.connect(db_file)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# --- Create the 'employees' Table ---\n",
        "# Use \"IF NOT EXISTS\" to make the script re-runnable\n",
        "# Store complex fields (lists/dicts) as TEXT by converting them to JSON strings\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS employees (\n",
        "    employeeId TEXT PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    jobTitle TEXT,\n",
        "    department TEXT,\n",
        "    email TEXT,\n",
        "    yearsOfExperience INTEGER,\n",
        "    availability TEXT,\n",
        "    manager TEXT,\n",
        "    location TEXT,\n",
        "    certifications TEXT,\n",
        "    skills TEXT,\n",
        "    projectHistory TEXT\n",
        ");\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "print(\"Table 'employees' created or already exists.\")\n",
        "\n",
        "# --- Insert Data into the Table ---\n",
        "insert_count = 0\n",
        "for employee in employee_data:\n",
        "    # Use \"INSERT OR REPLACE\" to handle re-running the script. It will update records if the employeeId already exists.\n",
        "    insert_query = \"\"\"\n",
        "    INSERT OR REPLACE INTO employees (\n",
        "        employeeId, name, jobTitle, department, email, yearsOfExperience,\n",
        "        availability, manager, location, certifications, skills, projectHistory\n",
        "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\n",
        "    \"\"\"\n",
        "    # Convert lists and dicts to JSON strings for storage\n",
        "    data_tuple = (\n",
        "        employee.get('employeeId'),\n",
        "        employee.get('name'),\n",
        "        employee.get('jobTitle'),\n",
        "        employee.get('department'),\n",
        "        employee.get('email'),\n",
        "        employee.get('yearsOfExperience'),\n",
        "        employee.get('availability'),\n",
        "        employee.get('manager'),\n",
        "        employee.get('location'),\n",
        "        json.dumps(employee.get('certifications', [])),\n",
        "        json.dumps(employee.get('skills', [])),\n",
        "        json.dumps(employee.get('projectHistory', []))\n",
        "    )\n",
        "    cursor.execute(insert_query, data_tuple)\n",
        "    insert_count += 1\n",
        "\n",
        "# --- Commit Changes and Close Connection ---\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(f\"--- Process Complete ---\")\n",
        "print(f\"Successfully inserted/updated {insert_count} records into '{db_file}'.\")\n",
        "print(\"Your database is now ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2X-Qu0xKrnz",
        "outputId": "ddba9019-d853-492e-9c90-6b07c9b359a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 30 records from employees.json\n",
            "Table 'employees' created or already exists.\n",
            "--- Process Complete ---\n",
            "Successfully inserted/updated 30 records into 'employees.db'.\n",
            "Your database is now ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "db_file = 'employees.db'\n",
        "\n",
        "# Connect to the database\n",
        "conn = sqlite3.connect(db_file)\n",
        "# Use a Row factory to get results as dictionary-like objects\n",
        "conn.row_factory = sqlite3.Row\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch the first 3 employees\n",
        "cursor.execute(\"SELECT * FROM employees LIMIT 5;\")\n",
        "records = cursor.fetchall()\n",
        "\n",
        "print(f\"--- Verifying first {len(records)} records from the database ---\")\n",
        "for record in records:\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Name: {record['name']} ({record['jobTitle']})\")\n",
        "    print(f\"Email: {record['email']}\")\n",
        "\n",
        "    # Demonstrate parsing the JSON string back into a Python object\n",
        "    skills_list = json.loads(record['skills'])\n",
        "    print(f\"Skills: {[s['skill'] for s in skills_list]}\")\n",
        "\n",
        "    # Print the raw project history JSON string\n",
        "    print(f\"Project History (raw JSON): {record['projectHistory']}\")\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTLCwttxKvWP",
        "outputId": "3adb380b-a07a-4ed2-dacd-22bd3b6ef556"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying first 5 records from the database ---\n",
            "--------------------\n",
            "Name: Priya Sharma (Senior Software Engineer)\n",
            "Email: priya.sharma@example.com\n",
            "Skills: ['Python', 'AWS', 'Java', 'REST APIs', 'Microservices']\n",
            "Project History (raw JSON): [{\"projectName\": \"Project QuantumLeap Backend\", \"description\": \"Led development of core microservices, improving API response time by 40%.\"}, {\"projectName\": \"Orion Data Pipeline\", \"description\": \"Optimized data processing scripts in Python, reducing runtime by 30%.\"}]\n",
            "--------------------\n",
            "Name: David Chen (Data Analyst)\n",
            "Email: david.chen@example.com\n",
            "Skills: ['SQL', 'Tableau', 'Python', 'Data Visualization', 'Customer Retention Analysis']\n",
            "Project History (raw JSON): [{\"projectName\": \"Q3 Sales Performance Analysis\", \"description\": \"Created interactive dashboards to track key sales KPIs for executive review.\"}, {\"projectName\": \"Customer Churn Prediction Model\", \"description\": \"Assisted data science team by cleaning and preparing data for a predictive model.\"}]\n",
            "--------------------\n",
            "Name: Maria Garcia (Senior Project Manager)\n",
            "Email: maria.garcia@example.com\n",
            "Skills: ['Agile Methodology', 'Scrum', 'Stakeholder Communication', 'Risk Management', 'Jira']\n",
            "Project History (raw JSON): [{\"projectName\": \"Project Phoenix Launch\", \"description\": \"Managed a cross-functional team of 15 to ensure on-time, on-budget delivery of a major product.\"}, {\"projectName\": \"Mobile App Revamp\", \"description\": \"Oversaw complete project lifecycle for the V2 mobile app, from conception to App Store release.\"}]\n",
            "--------------------\n",
            "Name: Ben Carter (DevOps Engineer)\n",
            "Email: ben.carter@example.com\n",
            "Skills: ['CI/CD', 'Docker', 'Kubernetes', 'Terraform', 'System Monitoring']\n",
            "Project History (raw JSON): [{\"projectName\": \"Infrastructure as Code Initiative\", \"description\": \"Led the migration of legacy server infrastructure to Terraform scripts on AWS.\"}, {\"projectName\": \"CI/CD Pipeline Automation\", \"description\": \"Built and maintained automated testing and deployment pipelines for 5 key applications.\"}]\n",
            "--------------------\n",
            "Name: Dr. Evelyn Reed (Lead Data Scientist)\n",
            "Email: evelyn.reed@example.com\n",
            "Skills: ['Machine Learning', 'Python', 'R', 'Natural Language Processing (NLP)', 'Deep Learning']\n",
            "Project History (raw JSON): [{\"projectName\": \"Customer Sentiment Analysis Engine\", \"description\": \"Developed an NLP model to analyze customer feedback, improving product strategy.\"}, {\"projectName\": \"Sales Forecasting Model\", \"description\": \"Built a time-series model to predict quarterly sales with 92% accuracy.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-docx\n",
        "!pip install langchain_google_genai\n",
        "!pip install pypdf\n",
        "%pip install langgraph\n",
        "%pip install -U langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9PhovU8NK0N4",
        "outputId": "49a3f5b6-243b-4237-b8ca-6a2f6a19c423"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/253.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.69)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6fc7d56b5a99413f8d7747d6fa81fe03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.8.0\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.69)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.73-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.5.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 ormsgpack-1.10.0\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.69)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg153WL7M16d",
        "outputId": "ac386d51-b45e-4191-828a-44228f05bea9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "oCLOI-URM-wC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpysE5q9NC2y",
        "outputId": "5f5b3f5b-7987-4b5b-e9a0-623338ea4b3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--76ccc0dd-bcd7-437b-9a7b-358490272e23-0', usage_metadata={'input_tokens': 20, 'output_tokens': 7, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "import sqlite3\n",
        "import json\n",
        "from langchain.tools import tool\n",
        "from pypdf import PdfReader\n",
        "from docx import Document\n",
        "\n",
        "@tool\n",
        "def search_employees(\n",
        "    job_titles: list[str] | None = None,\n",
        "    skills: list[str] | None = None,\n",
        "    department: str | None = None,\n",
        "    availability: str | None = None,\n",
        "    skill_search_mode: str = 'AND'\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Searches the employee database.\n",
        "    - 'job_titles': Finds employees matching ANY title (OR search).\n",
        "    - 'skills': Finds employees matching skills based on 'skill_search_mode'.\n",
        "    - 'skill_search_mode': Use 'AND' to find employees with ALL listed skills. Use 'OR' to find employees with ANY of the skills. Defaults to 'AND'.\n",
        "    - 'department', 'availability' are filters.\n",
        "    Returns a JSON string of matching profiles.\n",
        "    \"\"\"\n",
        "    db_file = 'employees.db'\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    query = \"SELECT * FROM employees WHERE 1=1\"\n",
        "    params = []\n",
        "\n",
        "    if job_titles:\n",
        "        title_conditions = [f\"LOWER(jobTitle) LIKE ?\" for title in job_titles]\n",
        "        query += f\" AND ({' OR '.join(title_conditions)})\"\n",
        "        params.extend([f\"%{title.lower()}%\" for title in job_titles])\n",
        "\n",
        "    if department:\n",
        "        query += \" AND LOWER(department) LIKE ?\"\n",
        "        params.append(f\"%{department.lower()}%\")\n",
        "\n",
        "    if availability:\n",
        "        query += \" AND LOWER(availability) = ?\"\n",
        "        params.append(availability.lower())\n",
        "\n",
        "    # --- NEW: Logic for AND/OR skill search ---\n",
        "    if skills:\n",
        "        skill_queries = [f\"LOWER(skills) LIKE ?\" for _ in skills]\n",
        "        skill_params = [f'%\\\"skill\\\": \\\"{skill.lower()}%' for skill in skills]\n",
        "\n",
        "        if skill_search_mode.upper() == 'OR':\n",
        "            query += f\" AND ({' OR '.join(skill_queries)})\"\n",
        "            params.extend(skill_params)\n",
        "        # else: # Default to AND\n",
        "        #     query += f\" AND {' AND '.join(skill_queries)}\"\n",
        "        #     params.extend(skill_params)\n",
        "\n",
        "    cursor.execute(query, tuple(params))\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    results = [dict(row) for row in rows]\n",
        "    for r in results:\n",
        "        r['certifications'] = json.loads(r['certifications'])\n",
        "        r['skills'] = json.loads(r['skills'])\n",
        "        r['projectHistory'] = json.loads(r['projectHistory'])\n",
        "\n",
        "    return json.dumps(results, indent=2)\n",
        "\n",
        "# This tool remains the same\n",
        "@tool\n",
        "def read_document(file_path: str) -> str:\n",
        "    # ... (code for read_document is unchanged)\n",
        "    \"\"\"Reads text from PDF, DOCX, or TXT.\"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        if file_path.lower().endswith('.pdf'):\n",
        "            reader = PdfReader(file_path)\n",
        "            for page in reader.pages: text += page.extract_text() or \"\"\n",
        "        elif file_path.lower().endswith('.docx'):\n",
        "            doc = Document(file_path)\n",
        "            for para in doc.paragraphs: text += para.text + \"\\n\"\n",
        "        elif file_path.lower().endswith('.txt'):\n",
        "            with open(file_path, 'r') as f: text = f.read()\n",
        "        else: return \"Error: Unsupported file type. Use .pdf, .docx, or .txt.\"\n",
        "        return f\"Successfully read document '{file_path}'. Content:\\n\\n{text}\"\n",
        "    except Exception as e: return f\"Error reading document: {e}\"\n",
        "\n",
        "\n",
        "tools = [search_employees, read_document]\n",
        "print(\"✅ Tools upgraded with flexible skill search mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekvnyxDwK4tF",
        "outputId": "5d803f50-ff6d-4c85-c73d-9b351c61c3d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tools upgraded with flexible skill search mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "# from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.messages import BaseMessage, ToolMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "import operator\n",
        "\n",
        "# 1. Define the Agent's State (remains the same)\n",
        "class AgentState(dict):\n",
        "    messages: Annotated[list[BaseMessage], operator.add]\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In Notebook Cell 5, find the system_prompt definition and replace it with this:\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a world-class AI Staffing Assistant. Your mission is to find the best person for a project using a strategic, multi-step search process.\n",
        "\n",
        "**Your Search and Analysis Procedure (MUST be followed):**\n",
        "\n",
        "**1. Initial Strict Search:**\n",
        "   - First, identify all the key skills required from the user's request and any documents.\n",
        "   - Perform a search using the `search_employees` tool with `skill_search_mode='AND'`. This is your attempt to find the \"perfect\" candidate who has every required skill.\n",
        "\n",
        "**2. Fallback Lenient Search (If necessary):**\n",
        "   - **IF AND ONLY IF** your initial 'AND' search returns no results, you MUST perform a second, broader search.\n",
        "   - For this second search, identify the 2-3 most critical skills and use the tool with `skill_search_mode='OR'`.\n",
        "   - Acknowledge to yourself that a perfect candidate was not found and you are now looking for the \"best fit\" from a wider pool.\n",
        "\n",
        "**3. Holistic Analysis & Recommendation:**\n",
        "   - Analyze the candidates returned from your successful search (either the 'AND' or the 'OR' search).\n",
        "   - Compare their full profiles: skills proficiency, relevant project history, and experience.\n",
        "   - Select the single best candidate.\n",
        "\n",
        "**4. Formulate the Final Answer:**\n",
        "   - Present your final answer using the structured format below.\n",
        "   - If you had to use the fallback 'OR' search, you MUST state this in your justification (e.g., \"While no single candidate possessed all the required skills, Priya Sharma has the best coverage...\").\n",
        "\n",
        "**Final Answer Format:**\n",
        "\n",
        "**Recommendation:**\n",
        "[Name of the single best candidate and their Job Title]\n",
        "\n",
        "**Overall Justification:**\n",
        "[Detailed paragraph explaining WHY this person is the top choice. Explain your search process if you used the fallback.]\n",
        "\n",
        "**Key Strengths:**\n",
        "- [Bulleted list of their most relevant skills and projects.]\n",
        "\n",
        "**Other Strong Candidates Considered:**\n",
        "- [Briefly mention 1-2 other candidates and why they were not the top pick.]\n",
        "\"\"\"\n",
        "\n",
        "# The rest of Cell 5 (compiling the graph) remains the same.\n",
        "# Make sure to re-run Cell 5 after this change.\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent = prompt | llm_with_tools\n",
        "\n",
        "# 4. Define Graph and Compile (remains the same)\n",
        "def agent_node(state: AgentState):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [result]}\n",
        "\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "def should_continue(state: AgentState) -> str:\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return \"end\"\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"agent\", agent_node)\n",
        "graph.add_node(\"tools\", tool_node)\n",
        "graph.set_entry_point(\"agent\")\n",
        "graph.add_conditional_edges(\n",
        "    \"agent\", should_continue, {\"tools\": \"tools\", \"end\": END},\n",
        ")\n",
        "graph.add_edge(\"tools\", \"agent\")\n",
        "app = graph.compile()\n",
        "print(\"✅ Final agent compiled with SKILL-FIRST search strategy!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TXePsOMLBIi",
        "outputId": "d2e9da90-dc8e-49cb-9f4f-22dea2c35030"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final agent compiled with SKILL-FIRST search strategy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A query where the job title is a suggestion, not a hard rule.\n",
        "# nuanced_query = \"I need someone who is an expert with Tableau for a customer retention analysis project. I think a Data Analyst would probably be best, but I'm open to other roles if they have the right skills. They must be available.\"\n",
        "nuanced_query =\"Find me an available Data Analyst with Tableau skills.\"\n",
        "inputs = {\"messages\": [HumanMessage(content=nuanced_query)]}\n",
        "\n",
        "print(\"\\n--- Running Nuanced, Skill-First Query ---\")\n",
        "for s in app.stream(inputs, stream_mode=\"values\"):\n",
        "    last_message = s[\"messages\"][-1]\n",
        "    if isinstance(last_message, ToolMessage):\n",
        "        print(\"\\n--- Tool Call ---\")\n",
        "        # You should see the tool call WITHOUT the job_titles parameter!\n",
        "        print(last_message.pretty_print())\n",
        "    elif last_message.content:\n",
        "        print(\"\\n--- Agent Output ---\")\n",
        "        print(last_message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWfz6I8NNitz",
        "outputId": "7f4eb50c-b022-4df1-e3ce-d6e14670c3c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Nuanced, Skill-First Query ---\n",
            "\n",
            "--- Agent Output ---\n",
            "Find me an available Data Analyst with Tableau skills.\n",
            "\n",
            "--- Tool Call ---\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_employees\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"employeeId\": \"1002\",\n",
            "    \"name\": \"David Chen\",\n",
            "    \"jobTitle\": \"Data Analyst\",\n",
            "    \"department\": \"Business Intelligence\",\n",
            "    \"email\": \"david.chen@example.com\",\n",
            "    \"yearsOfExperience\": 4,\n",
            "    \"availability\": \"Available\",\n",
            "    \"manager\": \"Emily White\",\n",
            "    \"location\": \"New York (EST)\",\n",
            "    \"certifications\": [\n",
            "      \"Tableau Desktop Specialist\"\n",
            "    ],\n",
            "    \"skills\": [\n",
            "      {\n",
            "        \"skill\": \"SQL\",\n",
            "        \"proficiency\": \"Expert\"\n",
            "      },\n",
            "      {\n",
            "        \"skill\": \"Tableau\",\n",
            "        \"proficiency\": \"Advanced\"\n",
            "      },\n",
            "      {\n",
            "        \"skill\": \"Python\",\n",
            "        \"proficiency\": \"Intermediate\"\n",
            "      },\n",
            "      {\n",
            "        \"skill\": \"Data Visualization\",\n",
            "        \"proficiency\": \"Expert\"\n",
            "      },\n",
            "      {\n",
            "        \"skill\": \"Customer Retention Analysis\",\n",
            "        \"proficiency\": \"Intermediate\"\n",
            "      }\n",
            "    ],\n",
            "    \"projectHistory\": [\n",
            "      {\n",
            "        \"projectName\": \"Q3 Sales Performance Analysis\",\n",
            "        \"description\": \"Created interactive dashboards to track key sales KPIs for executive review.\"\n",
            "      },\n",
            "      {\n",
            "        \"projectName\": \"Customer Churn Prediction Model\",\n",
            "        \"description\": \"Assisted data science team by cleaning and preparing data for a predictive model.\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "None\n",
            "\n",
            "--- Agent Output ---\n",
            "**Recommendation:**\n",
            "David Chen, Data Analyst\n",
            "\n",
            "**Overall Justification:**\n",
            "David Chen is the ideal candidate. He is currently available, holds the job title of Data Analyst, and possesses expert-level skills in SQL and Data Visualization, advanced proficiency in Tableau, and intermediate proficiency in Python. His project history includes creating interactive dashboards and assisting with data preparation for predictive modeling.\n",
            "\n",
            "**Key Strengths:**\n",
            "- **Tableau:** Advanced proficiency and a Tableau Desktop Specialist certification.\n",
            "- **Data Analysis & Visualization:** Expert-level skills.\n",
            "- **Project History:** Experience creating sales KPI dashboards.\n",
            "- **Availability:** Currently available.\n",
            "\n",
            "**Other Strong Candidates Considered:**\n",
            "There were no other candidates found with the specified criteria.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create a dummy project requirements .docx file ---\n",
        "from docx import Document\n",
        "from langchain_core.messages import HumanMessage, ToolMessage # Make sure these are imported if running the cell standalone\n",
        "\n",
        "# Define the file path and content\n",
        "docx_path = \"project_phoenix_requirements.docx\"\n",
        "project_title = \"Project Name: Project Phoenix\"\n",
        "project_goal = \"Goal: Develop a new cloud-native customer analytics platform.\"\n",
        "\n",
        "key_requirements = [\n",
        "    \"Must be built on AWS cloud infrastructure.\",\n",
        "    \"The backend needs to be developed using microservices architecture. Python is the preferred language.\",\n",
        "    \"The system must handle real-time data processing.\",\n",
        "    \"A strong focus on security and infrastructure-as-code (IaC) is required. We need engineers familiar with Terraform or similar tools.\",\n",
        "    \"We also need a Senior Project Manager with experience in Agile/Scrum to lead the effort.\"\n",
        "]\n",
        "\n",
        "# Create a new Word document\n",
        "doc = Document()\n",
        "\n",
        "# Add content to the document\n",
        "doc.add_heading(project_title, level=1)\n",
        "doc.add_paragraph(project_goal)\n",
        "doc.add_heading(\"Key Requirements:\", level=2)\n",
        "for item in key_requirements:\n",
        "    doc.add_paragraph(item, style='List Bullet')\n",
        "\n",
        "# Save the document\n",
        "doc.save(docx_path)\n",
        "print(f\"✅ Successfully created dummy project document: '{docx_path}'\")\n",
        "\n",
        "\n",
        "# --- Run the complex query with the new DOCX file ---\n",
        "query = f\"I'm staffing for Project Phoenix. Please review the requirements in the document '{docx_path}' and find me the best available engineers and a project manager.\"\n",
        "inputs = {\"messages\": [HumanMessage(content=query)]}\n",
        "\n",
        "print(\"\\n--- Running Complex Query with DOCX Document ---\")\n",
        "for s in app.stream(inputs, stream_mode=\"values\"):\n",
        "    last_message = s[\"messages\"][-1]\n",
        "    if isinstance(last_message, ToolMessage):\n",
        "        print(\"\\n--- Tool Call ---\")\n",
        "        print(last_message.pretty_print())\n",
        "    elif last_message.content:\n",
        "        print(\"\\n--- Agent Output ---\")\n",
        "        print(last_message.content)"
      ],
      "metadata": {
        "id": "3gi6DD1m66To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHLZkXcssL25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}